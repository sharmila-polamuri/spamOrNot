{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import model_selection\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vesrions of imported libraries\n",
      "Python  :- 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "NLTK :- 3.4.5\n",
      "Pandas :- 0.25.1\n",
      "Numpy :- 1.16.4\n"
     ]
    }
   ],
   "source": [
    "# check versions\n",
    "print(\"Vesrions of imported libraries\")\n",
    "print(f\"Python  :- {sys.version}\")\n",
    "print(f\"NLTK :- {nltk.__version__}\")\n",
    "# print(f\"Scikit-learn :- {sklearn.vesrion()}\")\n",
    "print(f\"Pandas :- {pd.__version__}\")\n",
    "print(f\"Numpy :- {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "def load_data(datapath):\n",
    "    \"\"\"\n",
    "    Input :- path of file\n",
    "    output :-  Load file to pandas dataframe\n",
    "    \"\"\"\n",
    "    dataset = pd.read_table(datapath, header=None, encoding=\"utf-8\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing module\n",
    "def preprocessing(labels, text):\n",
    "    \"\"\"\n",
    "    Input :- lables and text field\n",
    "    Output :- encoded labels and preprocessing text\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    Y = encoder.fit_transform(labels)\n",
    "    # replace email links with email \n",
    "    processed = text.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "    # Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    # Replace numbers with 'numbr'\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    # change words to lower case - Hello, HELLO, hello are all the same word\n",
    "    processed = processed.str.lower()\n",
    "\n",
    "    return Y, processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Input :- lables and text field\n",
    "    Output :- encoded labels and preprocessing text\n",
    "    \"\"\"\n",
    "    # replace email links with email \n",
    "    processed = text.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "    # Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    # Replace numbers with 'numbr'\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    # change words to lower case - Hello, HELLO, hello are all the same word\n",
    "    processed = processed.str.lower()\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(preprocess_data):\n",
    "    \"\"\"\n",
    "    remove stop words from input text\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preprocess_data = preprocess_data.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "    return preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stem(preprocess_data):\n",
    "    \"\"\"\n",
    "    applying word stemming technique to text\n",
    "    \"\"\"\n",
    "    porterstem = nltk.PorterStemmer()\n",
    "    preprocess_data = preprocess_data.apply(lambda x:' '.join(porterstem.stem(term) for term in x.split()))\n",
    "    return preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tokens(preprocess_data):\n",
    "    \"\"\"\n",
    "    Input :- preprocess data \n",
    "    Output :-  word tokens\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for sent in preprocess_data:\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            all_words.append(word)\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(sent,word_features):\n",
    "    \"\"\"\n",
    "    The find_features function will determine which of the 1500 word features are contained in the review\n",
    "    \"\"\"\n",
    "    words = word_tokenize(sent)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_model(training, testing):\n",
    "    \"\"\"\n",
    "    Training a svc model from nltk\n",
    "    \"\"\"\n",
    "    # model = SklearnClassifier(SVC(kernal = 'linear'))\n",
    "    model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "    # train the model on training data\n",
    "    model.train(training)\n",
    "    # test model on testing data\n",
    "    accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "    # result = model.classify(\"You won 100000000 rupee\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_models(training, testing):\n",
    "    \"\"\"\n",
    "    train different models on training data and then test on testing data\n",
    "    \"\"\"\n",
    "    # Define models to train\n",
    "    names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "    \n",
    "    classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "    ]\n",
    "    models = list(zip(names, classifiers))\n",
    "    for name, model in models:\n",
    "        nltk_model = SklearnClassifier(model)\n",
    "        nltk_model.train(training)\n",
    "        accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "        print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n",
      "[0 0 1 0 0]\n",
      "0    go until jurong point crazy available only in ...\n",
      "1                              ok lar joking wif u oni\n",
      "2    free entry in numbr a wkly comp to win fa cup ...\n",
      "3          u dun say so early hor u c already then say\n",
      "4    nah i don t think he goes to usf he lives arou...\n",
      "Name: 1, dtype: object\n",
      "0    go jurong point crazy available bugis n great ...\n",
      "1                              ok lar joking wif u oni\n",
      "2    free entry numbr wkly comp win fa cup final tk...\n",
      "3                  u dun say early hor u c already say\n",
      "4               nah think goes usf lives around though\n",
      "Name: 1, dtype: object\n",
      "0    go jurong point crazi avail bugi n great world...\n",
      "1                                ok lar joke wif u oni\n",
      "2    free entri numbr wkli comp win fa cup final tk...\n",
      "3                  u dun say earli hor u c alreadi say\n",
      "4                 nah think goe usf live around though\n",
      "Name: 1, dtype: object\n",
      "Number of words 6579\n",
      "Most common words [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n",
      "after all data zip go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n",
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data(\"smsspamcollection/SMSSpamCollection\")\n",
    "print(dataset.head())\n",
    "print(dataset.info())\n",
    "# count of sentences of each label\n",
    "labels = dataset[0]\n",
    "print(labels.value_counts())\n",
    "# data preprocessing\n",
    "Y, preprocess_data = preprocessing(labels, dataset[1])\n",
    "print(Y[:5])\n",
    "print(preprocess_data[:5])\n",
    "# remove stop words\n",
    "preprocess_data = remove_stopwords(preprocess_data)\n",
    "print(preprocess_data[:5])\n",
    "# apply stemming\n",
    "preprocess_data = word_stem(preprocess_data)\n",
    "print(preprocess_data[:5])\n",
    "# GATHERING features\n",
    "all_words = collect_tokens(preprocess_data)\n",
    "print(f\"Number of words {len(all_words)}\")\n",
    "print(f\"Most common words {all_words.most_common(15)}\")\n",
    "# user top most 1500 words as features\n",
    "word_features = list(all_words.keys())[:1500]\n",
    "# find features\n",
    "all_data_zip = list(zip(preprocess_data,Y))\n",
    "print(f\"after all data zip {preprocess_data[0]}\")\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(all_data_zip)\n",
    "#call find_features function for each SMS message\n",
    "featuresets = [(find_features(text, word_features), label)for (text, label) in all_data_zip]\n",
    "# split data into train and test data\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "# models training starts here\n",
    "svc_accuracy = svc_model(training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :- 98.77961234745155\n",
      "K Nearest Neighbors Accuracy: 95.19023689877962\n",
      "Decision Tree Accuracy: 97.84637473079684\n",
      "Random Forest Accuracy: 98.7078248384781\n",
      "Logistic Regression Accuracy: 98.49246231155779\n",
      "SGD Classifier Accuracy: 98.7078248384781\n",
      "Naive Bayes Accuracy: 97.98994974874373\n",
      "SVM Linear Accuracy: 98.77961234745155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy :- {svc_accuracy}\")\n",
    "# train on different models\n",
    "diff_models(training, testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
